[{"authors":null,"categories":null,"content":"Junjie Ye (in Chinese: 叶俊杰) received his B.Eng. degree in mechanical engineering from Tongji University, Shanghai, China. He is currently pursuing M.Sc. degree in mechanical engineering at Tongji University, Shanghai, China. His research interests include visual object tracking, deep learning, and robotics.\n","date":1618214400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1618214400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/junjie-ye/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/junjie-ye/","section":"authors","summary":"Junjie Ye (in Chinese: 叶俊杰) received his B.Eng. degree in mechanical engineering from Tongji University, Shanghai, China. He is currently pursuing M.Sc. degree in mechanical engineering at Tongji University, Shanghai, China.","tags":null,"title":"Junjie Ye","type":"authors"},{"authors":["Junjie Ye","Changhong Fu","Guangze Zheng","Ziang Cao","Bowen Li"],"categories":null,"content":"","date":1618214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618214400,"objectID":"c98ba9d164d6dc005d7f59a9f3dff2f1","permalink":"/publication/2021_iros_darklighter/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/publication/2021_iros_darklighter/","section":"publication","summary":"Recent years have witnessed the fast evolution and promising performance of the convolutional neural network (CNN)-based trackers, which aims at imitating biological visual systems. However, current CNN-based trackers can hardly generalize well to low-light scenes that are commonly lacked in the existing training set. In indistinguishable night scenarios frequently encountered in tracking-based applications on unmanned aerial vehicle (UAV), the robustness of the state-of-the-art trackers drops significantly. To facilitate aerial tracking in the dark through a general fashion, this work proposes an image enhancer namely DarkLighter, which dedicates to alleviate the impact of poor illumination conditions and noises iteratively. A lightweight network, i.e., LE-Net, is trained to efficiently estimate illumination layers and noise layers jointly. Experiments are conducted with several SOTA trackers on numerous UAV dark tracking scenarios. Exhaustive evaluations demonstrate the reliability and universality of DarkLighter, with high efficiency. Moreover, DarkLighter has further been implemented onboard a typical UAV system, real-world UAV tracking tests at night verify its practicability and dependability.","tags":["Low-light enhancement","Visual tracking","Unmanned aerial vehicles"],"title":"DarkLighter: Light up the Darkness for UAV Tracking","type":"publication"},{"authors":["Junjie Ye","Changhong Fu","Fuling Lin","Fangqiang Ding","Shan An","Geng Lu"],"categories":null,"content":"","date":1617753600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617753600,"objectID":"e2f8545841c2027482dc803fd972ebee","permalink":"/publication/2020_tie_mrcf-tracker/","publishdate":"2021-04-07T00:00:00Z","relpermalink":"/publication/2020_tie_mrcf-tracker/","section":"publication","summary":"Discriminative correlation filter (DCF)-based tracking approaches have shown prominent performance in unmanned aerial vehicle (UAV) tracking. Nevertheless, typical DCFs acquire all samples oriented to filter training merely from a raw image patch by cyclic shift operation in the spatial domain but ignore the consistency between samples across the timeline. The lack of temporal cues restricts the performance of DCFs under object appearance variations arising from object/UAV motion, scale variations, and viewpoint changes. Besides, many existing methods commonly neglect the channel discrepancy in object position estimation and generally treat all channels equally, thus limiting the further promotion of the tracking discriminability. To these concerns, this work proposes a novel tracking approach based on a multi-regularized correlation filter, i.e., MRCF tracker. By regularizing the deviation of responses and the reliability of channels, the tracker enables smooth response variations and adaptive channel weight distributions simultaneously, leading to favorable adaption to object appearance variations and enhancement of discriminability. Exhaustive experiments on four authoritative UAV-specific benchmarks validate the competitiveness and efficiency of MRCF against top-ranked trackers. Furthermore, we apply our proposed tracker to monocular UAV self-localization under air-ground robot coordination. Evaluations indicate the practicability of the present method in UAV localization applications.","tags":["Unmanned aerial vehicle (UAV)","Discriminative correlation filter (DCF)","Multi-regularization","Visual object tracking","UAV self-localization"],"title":"Multi-Regularized Correlation Filter for UAV Tracking and Self-Localization","type":"publication"},{"authors":["Bowen Li","Yiming Li","Junjie Ye","Changhong Fu","Hang Zhao"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"8f69f97ecf740fb99d1a9fb280cd8166","permalink":"/publication/2021_arxiv_pvt/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/publication/2021_arxiv_pvt/","section":"publication","summary":"As a crucial robotic perception capability, visual tracking has been intensively studied recently. In the real-world scenarios, the onboard processing time of the image streams inevitably leads to a discrepancy between the tracking results and the real-world states. However, existing visual tracking benchmarks commonly run the trackers offline and ignore such latency in the evaluation. In this work, we aim to deal with a more realistic problem of latency-aware tracking. The state-ofthe-art trackers are evaluated in the aerial scenarios with new metrics jointly assessing the tracking accuracy and efficiency. Moreover, a new predictive visual tracking baseline is developed to compensate for the latency stemming from the onboard computation. Our latency-aware benchmark can provide a more realistic evaluation of the trackers for the robotic applications. Besides, exhaustive experiments have proven the effectiveness of the proposed predictive visual tracking baseline approach. Our code is on https://github.com/vision4robotics/LAE-PVT-master.","tags":["Unmanned aerial vehicle","Visual object tracking","Latency-aware tracking"],"title":"Predictive Visual Tracking: A New Benchmark and Baseline Approach","type":"publication"},{"authors":["Bowen Li","Changhong Fu","Fangqiang Ding","Junjie Ye","Fuling Lin"],"categories":null,"content":"","date":1614499200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614499200,"objectID":"1433737504ce4cad2e1d5e6586c8e05f","permalink":"/publication/2021_icra_adtrack/","publishdate":"2021-02-28T08:00:00Z","relpermalink":"/publication/2021_icra_adtrack/","section":"publication","summary":"Prior correlation filter (CF)-based tracking methods for unmanned aerial vehicles (UAVs) have virtually focused on tracking in the daytime. However, when the night falls, the trackers will encounter more harsh scenes, which can easily lead to tracking failure. In this regard, this work proposes a novel tracker with anti-dark function (ADTrack). The proposed method integrates an effcient and effective low-light image enhancer into a CF-based tracker. Besides, a target-aware mask is simultaneously generated by virtue of image illumination variation. The target-aware mask can be applied to jointly train a target-focused filter that assists the context filter for robust tracking. Specifically, ADTrack adopts dual regression, where the context filter and the target-focused filter restrict each other for dual filter learning. Exhaustive experiments are conducted on typical dark sceneries benchmark, consisting of 37 typical night sequences from authoritative benchmarks, i.e., UAVDark, and our newly constructed benchmark UAVDark70. The results have shown that ADTrack favorably outperforms other state-of-the-art trackers and achieves a real-time speed of 34 frames/s on a single CPU, thus greatly extending robust UAV tracking to night scenes.","tags":["Visual tracking","Unmanned aerial vehicles","Correlation filter"],"title":"ADTrack: Target-Aware Dual Filter Learning for Real-Time Anti-Dark UAV Tracking","type":"publication"},{"authors":["Guangze Zheng","Changhong Fu","Junjie Ye","Fuling Lin","Fangqiang Ding"],"categories":null,"content":"","date":1614499200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614499200,"objectID":"2b51ed03d91fc1ed1d4cc28c2abf7736","permalink":"/publication/2021_icra_mscf_tracker/","publishdate":"2021-02-28T08:00:00Z","relpermalink":"/publication/2021_icra_mscf_tracker/","section":"publication","summary":"Unmanned aerial vehicle (UAV) based visual tracking has been confronted with numerous challenges, e.g., object motion and occlusion. These challenges generally bring about target appearance mutations and cause tracking failure. However, most prevalent discriminative correlation filter (DCF) based trackers are insensitive to target mutations due to a predefined label, which concentrates on merely the centre of the target. Meanwhile, appearance mutations incited by occlusion or similar objects commonly lead to inevitable learning of erroneous information. To cope with appearance mutations, this paper proposes a novel DCF-based method to enhance the sensitivity and resistance to mutations with an adaptive hybrid label, i.e., MSCF. The ideal label is optimized jointly with the correlation filter and remains consistent with the previous label. Meanwhile, a novel measurement of mutations called mutation threat factor (MTF) is applied to correct the label dynamically. Through the revision of label into hybrid shape, MSCF can demonstrate preferable adaptability during appearance mutations. Considerable experiments are conducted on widely used UAV benchmarks. Results manifest the performance of MSCF tracker surpassing other 26 state-ofthe-art DCF-based and deep-based trackers. With a real-time speed of ~ 38 frames/s, the proposed approach is sufficient for UAV tracking commissions.","tags":["Visual tracking","Unmanned aerial vehicles","Correlation filter"],"title":"Mutation Sensitive Correlation Filter for Real-Time UAV Tracking with Adaptive Hybrid Label","type":"publication"},{"authors":["Changhong Fu","Ziang Cao","Yiming Li","Junjie Ye","Chen Feng"],"categories":null,"content":"","date":1614499200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614499200,"objectID":"9e61feeea128ae22e4769a11f6af92fb","permalink":"/publication/2021_icra_siamapn/","publishdate":"2021-02-28T08:00:00Z","relpermalink":"/publication/2021_icra_siamapn/","section":"publication","summary":"In the domain of visual tracking, most deep learning-based trackers highlight the accuracy but casting aside efficiency, thereby impeding their real-world deployment on mobile platforms like the unmanned aerial vehicle (UAV). In this work, a novel two-stage siamese network-based method is proposed for aerial tracking, \\textit{i.e.}, stage-1 for high-quality anchor proposal generation, stage-2 for refining the anchor proposal. Different from anchor-based methods with numerous pre-defined fixed-sized anchors, our no-prior method can 1) make tracker robust and general to different objects with various sizes, especially to small, occluded, and fast-moving objects, under complex scenarios in light of the adaptive anchor generation, 2) make calculation feasible due to the substantial decrease of anchor numbers. In addition, compared to anchor-free methods, our framework has better performance owing to refinement at stage-2. Comprehensive experiments on three benchmarks have proven the state-of-the-art performance of our approach, with a speed of ~ 200 frames/s.","tags":["Visual tracking","Unmanned aerial vehicles","Anchor proposal network"],"title":"Siamese Anchor Proposal Network for High-Speed Aerial Tracking","type":"publication"},{"authors":["Bowen Li","Changhong Fu","Fangqiang Ding","Junjie Ye","Fuling Lin"],"categories":null,"content":"","date":1611446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611446400,"objectID":"a1378502c275eba58375066b33f246bc","permalink":"/publication/2021_arxiv_adtrack/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/publication/2021_arxiv_adtrack/","section":"publication","summary":"Visual object tracking, which is representing a major interest in image processing field, has facilitated numerous real world applications. Among them, equipping unmanned aerial vehicle (UAV) with real time robust visual trackers for all day aerial maneuver, is currently attracting incremental attention and has remarkably broadened the scope of applications of object tracking. However, prior tracking methods have merely focused on robust tracking in the well-illuminated scenes, while ignoring trackers' capabilities to be deployed in the dark. In darkness, the conditions can be more complex and harsh, easily posing inferior robust tracking or even tracking failure. To this end, this work proposed a novel discriminative correlation filter based tracker with illumination adaptive and anti dark capability, namely ADTrack. ADTrack firstly exploits image illuminance information to enable adaptability of the model to the given light condition. Then, by virtue of an efficient and effective image enhancer, ADTrack carries out image pretreatment, where a target aware mask is generated. Benefiting from the mask, ADTrack aims to solve a dual regression problem where dual filters, i.e., the context filter and target focused filter, are trained with mutual constraint. Thus ADTrack is able to maintain continuously favorable performance in all-day conditions. Besides, this work also constructed one UAV nighttime tracking benchmark UAVDark135, comprising of more than 125k manually annotated frames, which is also very first UAV nighttime tracking benchmark. Exhaustive experiments are extended on authoritative daytime benchmarks, i.e., UAV123 10fps, DTB70, and the newly built dark benchmark UAVDark135, which have validated the superiority of ADTrack in both bright and dark conditions on a single CPU.","tags":["Unmanned aerial vehicle","Visual object tracking","Discriminative correlation filter","Dark tracking benchmark","Image illumination based mask","Dual regression model"],"title":"All-Day Object Tracking for Unmanned Aerial Vehicle","type":"publication"},{"authors":null,"categories":null,"content":"Overview Exploit low-light enhancement, denoising, domain adaption technologies to adapt SOTA tracking approaches to low-light conditions. With slight computational consumption, enable UAV tracking at night.\n Papers with code Related works are presented as follows:\n  Designed a Retinex-inspired plug-and-play deep low-light enhancer, dubbed DarkLighter, to light up the darkness for UAV tracking. Experiments on a dark tracking benchmark verify its effectiveness in several trackers and superiority against other SOTA general low-light enhancement algorithms, with sufficient real-time speed on an embedded system.\n DarkLighter: Light up the Darkness for UAV Tracking submitted to IROS 2021\n   ","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"f19b501c492680ce0af90066772cfb0a","permalink":"/project/dark_tracking/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/project/dark_tracking/","section":"project","summary":"Adapt SOTA tracking approaches to low-light conditions.","tags":["Low-light","UAV tracking"],"title":"UAV Tracking at Night","type":"project"},{"authors":null,"categories":null,"content":"UAVDark135 is the very first UAV dark tracking benchmark dedicated to providing a comprehensive evaluation of tracking performance at night.\nUAVDark135 consists of 135 sequences, most of which were shot by a standard UAV at night, including more than 125k manually annotated frames. The benchmark covers a wide range of scenes, e.g., road, ocean, street, highway, and lakeside, including a large number of objects, such as person, car, building, athlete, truck, and bike.\nThe benchmark is available here (password: axci).\nUAVDark135 Tracking Benchmark A. Platform and Statistics Standing as the first UAV dark tracking benchmark, the UAVDark135 contains totally 135 sequences captured by a standard UAV2 at night. The benchmark includes various tracking scenes, e.g., crossings, t-junctions, road, highway, and consists of different kinds of tracked objects like people, boat, bus, car, truck, athletes, house, etc. To extent the covered scenes, the benchmark also contains some sequences from YouTube, which were shot on the sea. The total frames, mean frames, maximum frames, and minimum frames of the benchmark are 125466, 929, 4571, and 216 respectively, making it suitable for large-scale evaluation. The videos are captured at a frame-rate of 30 frames/s (FPS), with the resolution of 1920×1080.\nB. Annotation The frames in UAVDark135 are all manually annotated, where a sequence is completely processed by the same annotator to ensure consistency. Since in some dark scenes the object is nearly invisible, annotation process is much more strenuous. After the first round, 5 professional annotators carefully checked the results and made revision for several rounds to reduce errors as much as possible in nearly 2 months.\nSince the boundary contour of the object is not obvious in the dark, the result boxes of the first annotation fluctuates in continuous image frames. However, the actual motion process of the object should be smooth. In these considerations, we record the original annotation every 5 frames for the sequence with extremely severe vibration, and the results of the remaining frames are obtained by linear interpolation, which is closer to the position and scale variation of the real object.\nC. Attributes For more details, please refer to our paper.\n","date":1604102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604102400,"objectID":"2d77a9e9fdf8af223bcf640d5b739add","permalink":"/project/uavdark135/","publishdate":"2020-10-31T00:00:00Z","relpermalink":"/project/uavdark135/","section":"project","summary":"A pioneering UAV dark tracking benchmark consists of 135 videos with a variety of objects.","tags":["UAV dark tracking","Tracking benchmark"],"title":"UAVDark135","type":"project"},{"authors":["Changhong Fu","Junjie Ye","Juntao Xu","Yujie He","Fuling Lin"],"categories":null,"content":"","date":1602028800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602028800,"objectID":"06a2c27d3e614c9491702be79f0c1bcf","permalink":"/publication/2020_tgrs_ibri-tracker/","publishdate":"2020-10-07T00:00:00Z","relpermalink":"/publication/2020_tgrs_ibri-tracker/","section":"publication","summary":"Aerial object tracking approaches based on discriminative correlation filter (DCF) have attracted wide attention in the tracking community due to their impressive progress recently. Many studies introduce temporal regularization into the DCF-based framework to achieve a more robust appearance model and further enhance the tracking performance. However, existing temporal regularization approaches usually utilize the information of two consecutive frames, which are not robust enough due to limited information. Although some methods attempt to incorporate abundant training samples and generally improve the tracking performance, these improvements are at the expense of significantly increased computing consumption. Besides, most existing methods introduce historical information directly without denoising, which means background noises are also introduced into the filter training and may degrade the tracking accuracy. To tackle the drawbacks mentioned above, this work proposes a novel aerial object tracking approach to exploit disruptor-aware interval-based response inconsistency, i.e., IBRI tracker. The proposed method is able to incorporate historical interval information by utilizing responses in the filter training process, thereby obtaining a robust tracking performance while maintaining the real-time speed. Moreover, to reduce the disruptions caused by similar object, partial occlusion, and other challenging scenes, a novel disruptor-aware scheme based on response bucketing is introduced to detect the disruptor and enforce a spatial penalty for the disruptive area around the tracked object. Exhausted experiments on multiple well-known challenging aerial tracking benchmarks demonstrate the accuracy and robustness of the proposed IBRI tracker against other 35 state-of-the-art trackers. With a real-time speed of ~32 frames per second on a single CPU, the proposed approach can be applied for typical aerial platforms to achieve aerial visual object tracking efficiently.","tags":["Aerial object tracking","Discriminative correlation filter (DCF)","Temporal regularization","Historical frame information","Interval-based response inconsistency","Disruptor-aware bucketing"],"title":"Disruptor-Aware Interval-Based Response Inconsistency for Correlation Filters in Real-Time Aerial Tracking","type":"publication"},{"authors":null,"categories":null,"content":"Overview Construct robust Siamese network-based trackers for high-performance UAV tracking. Through enhancing the anchor proposal process, feature fusion strategy, attention mechanism, etc, we have developed several robust deep learning-based trackers for UAV.\n Papers with code Related works are presented as follows:\n  Proposed the anchor proposal network (APN) for adaptive anchor proposing. Alleviated the hyper-parameters in anchor-based approaches and redundent anchors in anchor-free approaches simultaneously.\n Siamese Anchor Proposal Network for High-Speed Aerial Tracking in ICRA 2021\n  Onboard Real-Time Aerial Tracking with Efficient Siamese Anchor Proposal Network submitted to IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING\n   Integrated self-attention and cross-attention into SiamAPN, enhanced the perception ability for various scale objects of the proposed SiamAPN++. Evaluation on UAV tracking datasets and real-world onboard test demonstrate its effectiveness.\n SiamAPN++: Siamese Attentional Aggregation Network for Real-Time UAV Tracking submitted to IROS 2021\n   ","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"5e3c002d4b38a9db457d3a43e536c5b5","permalink":"/project/siamesenetwork/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/project/siamesenetwork/","section":"project","summary":"Construct robust Siamese network-based trackers for high-performance UAV tracking.","tags":["Siamese Network","UAV tracking"],"title":"Siamese Network-Based UAV Tracking","type":"project"},{"authors":null,"categories":null,"content":"Overview Develop efficient and robust correlation filter (CF)-based trackers on CPU for UAV tracking in challenging scenarios. By mining temporal, spatial, and channel information properly, we have constructed several competitive tracking approaches while maintaining real-time performance on a single CPU.\n Papers with code Related works are presented as follows:\n  Introduced the temporal regularization based on historical interval response inconsistency and the disruptor-aware mechanism based on response bucketing into the CF framework, realizing competitive performance on several UAV tracking-specific benchmarks.\n Disruptor-Aware Interval-Based Response Inconsistency for Correlation Filters in Real-Time Aerial Tracking in IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING\n   Proposed the response deviation-aware regularization and the channel reliability aware regularization to make full use of the crucial information in response maps and reliable channels. Experiments demonstrate the proposed MRCF\u0026rsquo;s superiority in numerous challenging UAV tracking scenarios. Further, an original UAV self-localization system based on the proposed tracking approach is constructed.\n Multi-Regularized Correlation Filter for UAV Tracking and Self-Localization submitted to IEEE Transactions on Industrial Electronics\n   Constructed a novel DCF-based tracker to enhance the sensitivity and resistance to mutations with an adaptive hybrid label. Considerable experiments on widely used UAV tracking benchmarks demonstrate its effectiveness.\n Mutation Sensitive Correlation Filter for Real-Time UAV Tracking with Adaptive Hybrid Label in ICRA 2021\n   ","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"ea6be53db051cfae0845f1dd257f9a31","permalink":"/project/correlationfilterbasedvisualtracking/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/project/correlationfilterbasedvisualtracking/","section":"project","summary":"Develop efficient and robust trackers on CPU for UAV tracking in challenging scenarios.","tags":["Correlation filter","UAV tracking"],"title":"Correlation Filter-Based UAV Tracking","type":"project"}]